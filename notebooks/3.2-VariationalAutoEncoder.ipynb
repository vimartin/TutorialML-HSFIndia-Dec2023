{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wiso/TutorialML-AtlasItalia2022/blob/main/notebooks/3.2-VariationalAutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z39FPmEZPVaj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the dataset and preprocess"
      ],
      "metadata": {
        "id": "HeUtQoj741_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjeuSpmkPVao"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "nclasses = 10\n",
        "# preprocessing\n",
        "train_images = train_images / 255.\n",
        "test_images = test_images / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model\n",
        "The model is quite similar to the previous. The differnece is that the latent space is represented by random variables. We choose to distribute this random variables as independent normal distributions.\n",
        "\n",
        "In the loss we add a regularization term to impose that the latent space is distributed a the prior (independent normal distribution with average 0 and width 1)."
      ],
      "metadata": {
        "id": "vG5gzvqC5as3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EgYcplMPVap"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(tf.keras.models.Model):\n",
        "    def __init__(self, latent_dim, kl_weight=0.01):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.prior = tfp.distributions.Independent(tfp.distributions.Normal(loc=tf.zeros(latent_dim), scale=1), reinterpreted_batch_ndims=1)\n",
        "\n",
        "        # compute the number of parameters in the latest space (e.g. 2 * latent space dim, since we have the mean and the width)\n",
        "        latent_dim_params = tfp.layers.IndependentNormal.params_size(latent_dim)\n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(latent_dim_params, activation=None),  # this layer encode the means and the widths of the distributions\n",
        "            tfp.layers.IndependentNormal(\n",
        "                latent_dim,\n",
        "                activity_regularizer=tfp.layers.KLDivergenceRegularizer(self.prior, weight=kl_weight)),  # add the regularization\n",
        "        ])\n",
        "\n",
        "        self.decoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer(input_shape=[latent_dim]),\n",
        "            tf.keras.layers.Dense(7 * 7 * 64, activation='relu'),\n",
        "            tf.keras.layers.Reshape((7, 7, 64)),\n",
        "            tf.keras.layers.Conv2DTranspose(64, kernel_size=(3, 3), strides=(2, 2), padding='SAME', activation='relu'),\n",
        "            tf.keras.layers.Conv2DTranspose(32, kernel_size=(3, 3), strides=(2, 2), padding='SAME', activation='relu'),\n",
        "            tf.keras.layers.Conv2DTranspose(1, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation='sigmoid'),\n",
        "            tf.keras.layers.Reshape((28, 28))\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "\n",
        "latent_dim = 16\n",
        "kl_weight = 0.001  # with higher latent dim use smaller weight, e.g. 2 -> 0.01, 16 -> 0.0005\n",
        "autoencoder = Autoencoder(latent_dim, kl_weight)\n",
        "# take into account that the loss is the Huber loss plus the regularization terms\n",
        "autoencoder.compile(optimizer='adam', loss=tf.keras.losses.Huber(), metrics=tf.keras.losses.Huber())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "XgLZ7QMc6sz0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJGcr02lPVas"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(train_images, train_images,\n",
        "                epochs=10,\n",
        "                batch_size=512,\n",
        "                validation_data=(test_images, test_images),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model\n",
        "For each image in the test dataset, compute the encoded version (a sampling from the learned latent space distribution) and the decoded version"
      ],
      "metadata": {
        "id": "UHhNXEFp7DTq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z9mfccaPVas"
      },
      "outputs": [],
      "source": [
        "encoded_imgs = autoencoder.encoder(test_images)\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the encoded version of the first 20 images"
      ],
      "metadata": {
        "id": "9GckzWsh7k7Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWO4TfE-z58q"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 4))\n",
        "sns.heatmap(encoded_imgs[:20, :].numpy().T, ax=ax, square=True)\n",
        "plt.xlabel('image index')\n",
        "plt.ylabel('latent space')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check their distributions"
      ],
      "metadata": {
        "id": "pk4T0NpX76qy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT1_XrsVz58r"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(encoded_imgs.sample().numpy()[:, :10], bins=50, density=True, stacked=False, histtype='step', linewidth=1.5)\n",
        "xspace = np.linspace(-5, 5, 100)\n",
        "y = stats.norm(0, 1).pdf(xspace)\n",
        "ax.fill_between(xspace, y, color='0.7', zorder=-1, label='N[0,1]')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su2y_whrz58s"
      },
      "outputs": [],
      "source": [
        "n = 10\n",
        "fig = plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    ax = fig.add_subplot(2, n, i + 1)\n",
        "    ax.imshow(test_images[i], cmap='binary')\n",
        "    if i == 0:\n",
        "      ax.set_ylabel('original')\n",
        "    \n",
        "    ax = fig.add_subplot(2, n, i + 1 + n)\n",
        "    ax.imshow(decoded_imgs[i, :, :], cmap='binary')\n",
        "    if i == 0:\n",
        "      ax.set_ylabel('reconstructed')\n",
        "\n",
        "\n",
        "for ax in fig.get_axes():\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-RqCV2fPVau"
      },
      "outputs": [],
      "source": [
        "noise = autoencoder.prior.sample(10)\n",
        "decoded_imgs = autoencoder.decoder(noise)\n",
        "\n",
        "fig, axs = plt.subplots(1, 10, figsize=(20, 2))\n",
        "for ax, decoded_img in zip(axs.flat, decoded_imgs):\n",
        "    ax.imshow(decoded_img, cmap='binary')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 20\n",
        "\n",
        "fig, axs = plt.subplots(n, ncols=n, figsize=(15, 15))\n",
        "noise = np.random.multivariate_normal(np.zeros(latent_dim), np.eye(latent_dim))\n",
        "for inoise1, noise1 in enumerate(np.linspace(0.05, 0.95, n)):\n",
        "    for inoise2, noise2 in enumerate(np.linspace(0.05, 0.95, n)):\n",
        "        noise[0] = stats.norm(0, 1).ppf(noise1)\n",
        "        noise[1] = stats.norm(0, 1).ppf(noise2)\n",
        "        decoded_img = autoencoder.decoder(np.expand_dims(noise, axis=0)).numpy()[0]\n",
        "        axs[inoise1, inoise2].imshow(decoded_img, cmap='gray')\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect('equal')"
      ],
      "metadata": {
        "id": "Ff48SYtoZyyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpolate_and_show(test_image1, test_image2, decoder, encoder):\n",
        "    encoded1, encoded2 = encoder(np.stack([test_image1, test_image2])).mean().numpy()\n",
        "    t = np.expand_dims(np.linspace(0, 1, 10), axis=-1)\n",
        "    encoded_steps = encoded1 * (1 - t) + encoded2 * t\n",
        "\n",
        "    fig, axs = plt.subplots(1, 10 + 2, figsize=(15, 5))\n",
        "\n",
        "    axs[0].imshow(test_image1, cmap='binary')\n",
        "    axs[-1].imshow(test_image2, cmap='binary')\n",
        "    axs[0].set_title('first')\n",
        "    axs[-1].set_title('second')\n",
        "\n",
        "    for encoded_step, ax in zip(encoded_steps, axs[1:-1]):\n",
        "        img = decoder(np.expand_dims(encoded_step, axis=0)).numpy()[0]\n",
        "        ax.imshow(img, cmap='binary')\n",
        "\n",
        "    for ax in axs:    \n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_aspect('equal')\n",
        "\n",
        "for ilabel in range(nclasses):\n",
        "    test_image1 = test_images[test_labels == ilabel][0]\n",
        "    test_image2 = test_images[test_labels == ilabel][1]\n",
        "\n",
        "    interpolate_and_show(test_image1, test_image2, autoencoder.decoder, autoencoder.encoder)  "
      ],
      "metadata": {
        "id": "I8GLzTe-1awW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-er1WIaI4e6y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "1.1-ImageClassification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}