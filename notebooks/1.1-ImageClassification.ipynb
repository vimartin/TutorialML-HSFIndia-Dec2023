{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wiso/TutorialML-AtlasItalia2022/blob/main/notebooks/1.1-ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image classiciation with CNN\n",
        "Redo the same exercize using CNN"
      ],
      "metadata": {
        "id": "I8l5IDw78QdD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z39FPmEZPVaj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjeuSpmkPVao"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "nclasses = len(class_names)\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (train_images.shape, train_labels.shape))\n",
        "print('Test: X=%s, y=%s' % (test_images.shape, test_labels.shape))\n",
        "print(\"unique train labels=%s\" % np.unique(train_labels))\n",
        "print(\"range values first train img = %s, %s\" % (train_images[0].min(), train_images[0].max()))\n",
        "\n",
        "# preprocessing\n",
        "test_images = test_images / 255.\n",
        "train_images = train_images / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define several CNN models\n",
        "They are just a sequence of convolutional layers and max pooling layers. At the end the output of the filters is flatten and feeded to a simple dense neural network to do the multi class classification."
      ],
      "metadata": {
        "id": "wv9l6zPe8grF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e1ufm0DPVaq"
      },
      "outputs": [],
      "source": [
        "# 693,962 parameters, 30s training on GPU, 91.0% accuracy\n",
        "model_simpler = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "  \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(nclasses, activation='softmax'),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# kerasnet https://arxiv.org/pdf/1801.09403.pdf  594,922 parameters, 92.5% accuracy\n",
        "model_kerasnet = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(nclasses, activation='softmax'),\n",
        "])\n",
        "\n",
        "\n",
        "# ConvNet, accuracy 92.1%\n",
        "model_convnet = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                 data_format='channels_last', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                    data_format='channels_last'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                    data_format='channels_last'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                    data_format='channels_last'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(nclasses, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# LetNet5 61,706 parameters, accuracy 85%\n",
        "model_lenet5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.Resizing(32, 32, interpolation=\"bilinear\", input_shape=(28,28,1)),\n",
        "    tf.keras.layers.Conv2D(6, 5, activation='tanh', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.AveragePooling2D(2),\n",
        "    tf.keras.layers.Activation('sigmoid'),\n",
        "    tf.keras.layers.Conv2D(16, 5, activation='tanh'),\n",
        "    tf.keras.layers.AveragePooling2D(2),\n",
        "    tf.keras.layers.Activation('sigmoid'),\n",
        "    tf.keras.layers.Conv2D(120, 5, activation='tanh'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(84, activation='tanh'),\n",
        "    tf.keras.layers.Dense(nclasses, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# AlexNet 21,598,922 parameters, 15min training, accuracy: 91%\n",
        "model_alexnet = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=(28,28,1)),\n",
        "    tf.keras.layers.Conv2D(96, 11, strides=4, padding='same'),\n",
        "    tf.keras.layers.Lambda(tf.nn.local_response_normalization),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPooling2D(3, strides=2),\n",
        "    tf.keras.layers.Conv2D(256, 5, strides=4, padding='same'),\n",
        "    tf.keras.layers.Lambda(tf.nn.local_response_normalization),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPooling2D(3, strides=2),\n",
        "    tf.keras.layers.Conv2D(384, 3, strides=4, padding='same'),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.Conv2D(384, 3, strides=4, padding='same'),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.Conv2D(256, 3, strides=4, padding='same'),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(nclasses, activation='softmax'),\n",
        "])\n",
        "\n",
        "\n",
        "# as homework you can have a look to:\n",
        "# https://ai.plainenglish.io/vggnet-with-tensorflow-transfer-learning-with-vgg16-included-7e5f6fa9479a\n",
        "# https://ai.plainenglish.io/googlenet-inceptionv1-with-tensorflow-9e7f3a161e87\n",
        "# https://medium.com/swlh/resnet-with-tensorflow-transfer-learning-13ff0773cf0c\n",
        "# https://medium.com/swlh/essentials-of-convolutional-neural-networks-with-lenet-alexnet-vgg-googlenet-and-resnet-3f9dd477f666\n",
        "\n",
        "\n",
        "\n",
        "# choose here the model\n",
        "model = model_simpler\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJGcr02lPVas"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_images, train_labels, batch_size=512,\n",
        "                    epochs=50, validation_split=0.33,\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z9mfccaPVas"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
        "for ax, quantity in zip(axs, ('accuracy', 'loss')):\n",
        "    ax.plot(history.history[quantity], label='train')\n",
        "    ax.plot(history.history[f'val_{quantity}'], label='validation')\n",
        "    ax.legend()\n",
        "    ax.set_xlabel('epoch', fontsize=15)\n",
        "    ax.set_ylabel(quantity, fontsize=15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-RqCV2fPVau"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOhYZiqwPVav"
      },
      "outputs": [],
      "source": [
        "filters, bias = model.layers[0].get_weights()\n",
        "nfilters = filters.shape[-1]\n",
        "fig, axs = plt.subplots(4, nfilters // 4, figsize=(6, 3))\n",
        "for ifilter, ax in zip(range(nfilters), axs.flat):\n",
        "    ax.imshow(filters[:, :, 0, ifilter], cmap='bwr', vmin=-1, vmax=1)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect('equal')\n",
        "fig.subplots_adjust(wspace=0.1, hspace=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3s_cSwzPVav"
      },
      "outputs": [],
      "source": [
        "example_image = test_images[10]\n",
        "\n",
        "plt.imshow(example_image, cmap='binary')\n",
        "\n",
        "model_feature = tf.keras.models.Model(inputs=model.inputs , outputs=model.layers[0].output)\n",
        "features = model_feature.predict(np.expand_dims(example_image, 0))\n",
        "print(features.shape)\n",
        "nfilters = features.shape[-1]\n",
        "fig, axs = plt.subplots(4, nfilters // 4, figsize=(6, 3))\n",
        "for ifilter, ax in zip(range(nfilters), axs.flat):\n",
        "    ax.imshow(features[0, :, :, ifilter], cmap='gray', vmin=0, vmax=0.5)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect('equal')\n",
        "fig.subplots_adjust(wspace=0.1, hspace=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXU3WMnCPVaw"
      },
      "outputs": [],
      "source": [
        "output_predictions = model.predict(test_images)\n",
        "predicted_labels = np.argmax(output_predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ZmCpKrkRPVax"
      },
      "outputs": [],
      "source": [
        "mask_wrong = test_labels != predicted_labels\n",
        "wrong_images = test_images[mask_wrong]\n",
        "wrong_labels = test_labels[mask_wrong]\n",
        "wrong_predicted_labels = predicted_labels[mask_wrong]\n",
        "for idx in range(10):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(5, 2))\n",
        "    probs = tf.keras.layers.Softmax()(output_predictions[mask_wrong][idx]).numpy()\n",
        "    ax[0].bar(np.arange(len(probs)), probs)\n",
        "    ax[0].set_xticks(np.arange(len(probs)))\n",
        "    ax[0].set_xticklabels(class_names, rotation=90)\n",
        "    ax[0].get_xticklabels()[wrong_labels[idx]].set_color(\"red\")\n",
        "    ax[0].set_ylim(0, 1.1)\n",
        "    ax[0].set_yticklabels([])\n",
        "\n",
        "    ax[1].imshow(wrong_images[idx], cmap='binary')\n",
        "    ax[1].set_xticks([])\n",
        "    ax[1].set_yticks([])\n",
        "    fig.subplots_adjust(wspace=0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv3",
      "language": "python",
      "name": "venv3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "name": "1.1-ImageClassification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}