{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "nclasses = len(class_names)\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (train_images.shape, train_labels.shape))\n",
    "print('Test: X=%s, y=%s' % (test_images.shape, test_labels.shape))\n",
    "print(\"unique train labels=%s\" % np.unique(train_labels))\n",
    "print(\"range values first train img = %s, %s\" % (train_images[0].min(), train_images[0].max()))\n",
    "\n",
    "# preprocessing\n",
    "train_images = train_images / 255.\n",
    "test_images = test_images / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the numpy arrays to a tensorflow dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "#  tf.keras.layers.Lambda(lambda x: tf.reverse(x, axis=[-1]))\n",
    "])\n",
    "aug_ds = train_ds.map(lambda x, y: (resize_and_rescale(x, training=True), y))\n",
    "aug_ds = aug_ds.batch(32)\n",
    "aug_ds = aug_ds.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kerasnet https://arxiv.org/pdf/1801.09403.pdf  92.5% accuracy\n",
    "model_kerasnet = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(nclasses, activation='softmax'),\n",
    "])\n",
    "\n",
    "# 91.6% accuracy\n",
    "model_simpler = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "  \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(nclasses),\n",
    "])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Building a ConvNet\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
    "                 data_format='channels_last', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
    "                 data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
    "                 data_format='channels_last'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
    "                 data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model = model_simpler\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size=512,\n",
    "                    epochs=50, validation_split=0.33,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "for ax, quantity in zip(axs, ('accuracy', 'loss')):\n",
    "    ax.plot(history.history[quantity], label='train')\n",
    "    ax.plot(history.history[f'val_{quantity}'], label='validation')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('epoch', fontsize=15)\n",
    "    ax.set_ylabel(quantity, fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters, bias = model.layers[0].get_weights()\n",
    "nfilters = filters.shape[-1]\n",
    "fig, axs = plt.subplots(4, nfilters // 4, figsize=(6, 3))\n",
    "for ifilter, ax in zip(range(nfilters), axs.flat):\n",
    "    ax.imshow(filters[:, :, 0, ifilter], cmap='bwr', vmin=-1, vmax=1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect('equal')\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = test_images[10]\n",
    "\n",
    "plt.imshow(example_image, cmap='gray')\n",
    "\n",
    "model_feature = tf.keras.models.Model(inputs=model.inputs , outputs=model.layers[0].output)\n",
    "features = model_feature.predict(np.expand_dims(example_image, 0))\n",
    "print(features.shape)\n",
    "nfilters = features.shape[-1]\n",
    "fig, axs = plt.subplots(4, nfilters // 4, figsize=(6, 3))\n",
    "for ifilter, ax in zip(range(nfilters), axs.flat):\n",
    "    ax.imshow(features[0, :, :, ifilter], cmap='gray', vmin=0, vmax=0.5)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect('equal')\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(output_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mask_wrong = test_labels != predicted_labels\n",
    "wrong_images = test_images[mask_wrong]\n",
    "wrong_labels = test_labels[mask_wrong]\n",
    "wrong_predicted_labels = predicted_labels[mask_wrong]\n",
    "for idx in range(10):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(5, 2))\n",
    "    probs = tf.keras.layers.Softmax()(output_predictions[mask_wrong][idx]).numpy()\n",
    "    ax[0].bar(np.arange(len(probs)), probs)\n",
    "    ax[0].set_xticks(np.arange(len(probs)), class_names, rotation=90)\n",
    "    ax[0].get_xticklabels()[wrong_labels[idx]].set_color(\"red\")\n",
    "    ax[0].set_ylim(0, 1.1)\n",
    "    ax[0].set_yticklabels([])\n",
    "\n",
    "    ax[1].imshow(wrong_images[idx], cmap='gray')\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "    fig.subplots_adjust(wspace=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3",
   "language": "python",
   "name": "venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
