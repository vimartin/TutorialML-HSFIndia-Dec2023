{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, IFrame, YouTubeVideo, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Style transfer\n",
    "\n",
    "### In 2015\n",
    "\n",
    "```\n",
    "A Neural Algorithm of Artistic Style\n",
    "Leon A. Gatys, Alexander S. Ecker, Matthias Bethge\n",
    "```\n",
    "https://arxiv.org/abs/1508.06576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('-R9bJGNHltQ', 786, start=78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### In 2021\n",
    "\n",
    "```\n",
    "Enhancing Photorealism Enhancement\n",
    "Stephan R. Richter and Hassan Abu AlHaija and Vladlen Koltun\n",
    "```\n",
    "\n",
    "https://isl-org.github.io/PhotorealismEnhancement/\n",
    "https://arxiv.org/abs/2105.04619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('P1IcaBn3ej0', 786, start=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generative models\n",
    "\n",
    "### Generative Adversarial Networks\n",
    "\n",
    "GAN were first proposed by Goodfellow et al in 2014 [paper](https://arxiv.org/abs/1406.2661) and significantly improved using Wesseinstein distance [paper](https://arxiv.org/abs/1701.07875) and gradient penalty [paper](https://arxiv.org/pdf/1704.00028.pdf). They reached a high level of realism demonstrating their usability in real word application from NVIDIA in 2019 [paper](https://arxiv.org/pdf/1812.04948.pdf)\n",
    "\n",
    "![First GAN](imgs/GAN_faces.PNG)\n",
    "![Nvidia](imgs/NVIDIA_faces.jpg)\n",
    "\n",
    "The basic idea is to have two network competing; the generator produces images from noise while the discriminator tries to distinguish between real and fake (generated) images. Both network learn in parallel leading to a generator that can reproduce the images feed into the discriminator network. The learning is achievend via this constant competition like in game. The convergence of the training is therefore different from the usual minimisation problem typical of HEP and requires a different approach from the selection of the last trained network as this may not the best generator.\n",
    "\n",
    "### Variable Auto Encoders\n",
    "First proposed in 2013, VAE [paper](https://arxiv.org/abs/1312.6114) are a generative model that rewrites the inference problems as a statistical optimization problem. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepfake\n",
    "\n",
    "```\n",
    "First Order Motion Model for Image Animation\n",
    "Aliaksandr Siarohin, Stéphane Lathuilière, Sergey Tulyakov, Elisa Ricci and Nicu Sebe\n",
    "in NeurIPS 2019\n",
    "```\n",
    "\n",
    "https://aliaksandrsiarohin.github.io/first-order-model-website/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Image(\"https://aliaksandrsiarohin.github.io/first-order-model-website/vox-teaser.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Image(\"https://aliaksandrsiarohin.github.io/first-order-model-website/fashion-teaser.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Image(\"https://aliaksandrsiarohin.github.io/first-order-model-website/mgif-teaser.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate image from natural language\n",
    "\n",
    "```\n",
    "Hierarchical Text-Conditional Image Generation with CLIP Latents\n",
    "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen\n",
    "```\n",
    "https://arxiv.org/abs/2204.06125\n",
    "https://openai.com/dall-e-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reinforsment learning\n",
    "\n",
    "### Learn to jump\n",
    "```\n",
    "Discovering Diverse Athletic Jumping Strategies\n",
    "ZHIQI YIN, Simon Fraser University, Canada\n",
    "ZESHI YANG, Simon Fraser University, Canada\n",
    "MICHIEL VAN DE PANNE, University of British Columbia, Canada\n",
    "KANGKANG YIN, Simon Fraser University, Canada\n",
    "in ACM SIGGRAPH 2021\n",
    "```\n",
    "https://arpspoof.github.io/project/jump/jump.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('DAhZ6oDoNHg', 786, start=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learn to hide\n",
    "\n",
    "```\n",
    "Emergent Tool Use from Multi-Agent Interaction\n",
    "Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell, Bob McGrew, Igor Mordatch\n",
    "\n",
    "```\n",
    "https://arxiv.org/abs/1909.07528\n",
    "\n",
    "https://openai.com/blog/emergent-tool-use/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fast simulation\n",
    "\n",
    "### Turbolence\n",
    "\n",
    "```\n",
    "Predicting High-Resolution Turbulence Details in Space and Time\n",
    "KAI BAI, ShanghaiTech University/SIMIT/UCAS\n",
    "CHUNHAO WANG, ShanghaiTech University\n",
    "MATHIEU DESBRUN, Inria Saclay/Ecole Polytechnique/Caltech\n",
    "XIAOPEI LIU, ShanghaiTech University\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('dQMvii1KGOY', 786, start=210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```\n",
    "Learning Mesh-Based Simulation with Graph Networks\n",
    "Tobias Pfaff, Meire Fortunato, Alvaro Sanchez-Gonzalez, Peter W. Battaglia\n",
    "ICLR 2021 outstanding paper\n",
    "```\n",
    "https://arxiv.org/abs/2010.03409\n",
    "https://sites.google.com/view/meshgraphnets#h.g779vko02iww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('g7bEUB8aLvM', 786, start=310)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GPT-3\n",
    "\n",
    "```\n",
    "Language Models are Few-Shot Learners (OpenAI 2020).\n",
    "https://arxiv.org/abs/2005.14165\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"imgs/gpt3_higgs.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"imgs/gpt3_higgs2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"imgs/gpt3_higgs4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"imgs/gpt3_higgs3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"imgs/gpt3_higgs5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GPT-3 grade school math\n",
    "https://openai.com/blog/grade-school-math/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GPT-3 formal math\n",
    "\n",
    "```\n",
    "Formal Mathematics Statement Curriculum Learning (OpenAI 2022)\n",
    "https://arxiv.org/abs/2202.01344\n",
    "```\n",
    "\n",
    "https://openai.com/blog/formal-math/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## HEP\n",
    "Collection of ML paper by IML: https://iml-wg.github.io/HEPML-LivingReview/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "venv3",
   "language": "python",
   "name": "venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
