{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wiso/TutorialML-AtlasItalia2022/blob/main/notebooks/3.0-AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoder\n",
        "\n",
        "Simple autoencoder trained on fashion minst using a simple dense neural network"
      ],
      "metadata": {
        "id": "8iOX-BgPgKJV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z39FPmEZPVaj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjeuSpmkPVao"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# preprocessing\n",
        "train_images = train_images / 255.\n",
        "test_images = test_images / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model\n",
        "\n",
        "The model is made by two connected parts. The encoder transform the inputs (the pixel values) to the latent space. The decoder transform the latent space to the output image.\n",
        "\n",
        "The loss evaluate how the input and the output image are different."
      ],
      "metadata": {
        "id": "LQMxnYTqgccp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EgYcplMPVap"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(tf.keras.models.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim   \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "               tf.keras.layers.Flatten(),\n",
        "               tf.keras.layers.Dense(latent_dim, activation='relu'),\n",
        "        ])\n",
        "        self.decoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(28 * 28, activation='sigmoid'),\n",
        "            tf.keras.layers.Reshape((28, 28))\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "latent_dim = 64\n",
        "autoencoder = Autoencoder(latent_dim)\n",
        "autoencoder.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit?"
      ],
      "metadata": {
        "id": "ZCeMPg-TitwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJGcr02lPVas"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(train_images, train_images,\n",
        "                epochs=30,\n",
        "                batch_size=512,\n",
        "                shuffle=True,\n",
        "                validation_data=(test_images, test_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try the autoencoder on the test images"
      ],
      "metadata": {
        "id": "pDTNXSp1jBaM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z9mfccaPVas"
      },
      "outputs": [],
      "source": [
        "encoded_imgs = autoencoder.encoder(test_images).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the latent space for the first 20 images. Some values are always zero! It means it is not fully using the latest space! We should use some regularization to avoid it"
      ],
      "metadata": {
        "id": "ntMecur3jG4l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usG8WAeCqiNi"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 4))\n",
        "sns.heatmap(encoded_imgs[:20, :], ax=ax, square=True)\n",
        "ax.set_ylabel('image index')\n",
        "ax.set_xlabel('latent space')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution of the the values of the latest space, for all the images"
      ],
      "metadata": {
        "id": "x5sjrgY1jeDW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxbfleetqiNj"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.hist(encoded_imgs.flat, bins=100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to estimate the pdf of the latent space using the test images. Evaluate the means and covariance."
      ],
      "metadata": {
        "id": "o4ZGJPG7j17G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiEdiINWqiNk"
      },
      "outputs": [],
      "source": [
        "means = np.mean(encoded_imgs, axis=0)\n",
        "cov = np.cov(encoded_imgs.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the input and the output images"
      ],
      "metadata": {
        "id": "uRxoU7bTj9bg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-RqCV2fPVau"
      },
      "outputs": [],
      "source": [
        "n = 10\n",
        "fig = plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    ax = fig.add_subplot(2, n, i + 1)\n",
        "    ax.imshow(test_images[i], cmap='binary')\n",
        "    ax.set_title(\"original\")\n",
        "    \n",
        "    ax = fig.add_subplot(2, n, i + 1 + n)\n",
        "    ax.imshow(decoded_imgs[i], cmap='binary')\n",
        "    ax.set_title(\"reconstructed\")\n",
        "    \n",
        "for ax in fig.get_axes():\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate new images\n",
        "We can generate some noise and use it as latent space. We can apply the decoder to generate new images. The problem is that we don't know the distribution of the latent space. Let assume it is a multivariate normal distribution, using the mean and the covariance we computed."
      ],
      "metadata": {
        "id": "bRLGiRHokEyL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RIKQEFQqiNm"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 10, figsize=(15, 3))\n",
        "for ax in axs.flat:\n",
        "    noise = np.random.multivariate_normal(means, cov, size=(1,))\n",
        "    decoded_img = autoencoder.decoder(noise).numpy()[0]\n",
        "    ax.imshow(decoded_img, cmap='binary')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is not very satisfactory for several reason, for example we don't know the distribution of the latent space"
      ],
      "metadata": {
        "id": "09y5URw4kVVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpolate between two images\n",
        "Compute the latent representation of two input images and linear interpolate between them. Then apply the decoder."
      ],
      "metadata": {
        "id": "NpRGAQykkdVw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP4QaXqpqiNm"
      },
      "outputs": [],
      "source": [
        "nsteps = 10\n",
        "l = np.linspace(0, 1, 10)\n",
        "i = l * np.expand_dims(decoded_imgs[0], -1) + (1 - l) * np.expand_dims(decoded_imgs[1], -1)\n",
        "fig, axs = plt.subplots(1, nsteps, figsize=(15, 3))\n",
        "for ax, step in zip(axs.flat, range(nsteps)):\n",
        "    ax.imshow(i[:, :, step], cmap='binary')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qRA4sYNhw9wU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "1.1-ImageClassification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}